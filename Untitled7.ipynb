{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1T4auZb9bZY73S8SAd9T9CZ1FRJfhEXA5",
      "authorship_tag": "ABX9TyNhgLFto4KbLkC3gsCCvYsF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82fb4663c9c44d388c3da9d951e7d8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_40180660284f48afa9604181c151311e"
          }
        },
        "083071946c4c45608e7c93e2248f0c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6423d1cffa2a4582bdb7896b5dd2827e",
            "placeholder": "​",
            "style": "IPY_MODEL_162e370d98fa4a6cb4879a227f05fc1c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "7fb64a484b994b03ad0658d3eb731cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f2cc45f6d4cb48f08640f44df3a529f6",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa4133d88a04d6892bd06ac5f1cc8c7",
            "value": ""
          }
        },
        "5ffa0e61070e45348cca5a2432f4dfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ee164556a7ed4cfc8546acbece86ad51",
            "style": "IPY_MODEL_2dfa25e7c7494334a85d4790be9ef871",
            "value": true
          }
        },
        "b024849ee8cf4682ab4a8d1e3d4ca149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f33df85186c84cc98c39a2cf5ba46bc9",
            "style": "IPY_MODEL_13c56c36041e435498323a57d78f01f4",
            "tooltip": ""
          }
        },
        "8dd76c27952543abad8f18b14d07501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85e2fdb22344f44a14424ba0d1a886e",
            "placeholder": "​",
            "style": "IPY_MODEL_3fc4e292991e42f4a9c2a670f8026556",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "40180660284f48afa9604181c151311e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6423d1cffa2a4582bdb7896b5dd2827e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162e370d98fa4a6cb4879a227f05fc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2cc45f6d4cb48f08640f44df3a529f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa4133d88a04d6892bd06ac5f1cc8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee164556a7ed4cfc8546acbece86ad51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa25e7c7494334a85d4790be9ef871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f33df85186c84cc98c39a2cf5ba46bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c56c36041e435498323a57d78f01f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d85e2fdb22344f44a14424ba0d1a886e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc4e292991e42f4a9c2a670f8026556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc7ba7738b34e77882e4e28c305c7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84012aeb5dfd47279890d6101a9a0dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_681adafe802046758b2495a6274de87f",
            "value": "Connecting..."
          }
        },
        "84012aeb5dfd47279890d6101a9a0dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681adafe802046758b2495a6274de87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QueerAgent1/653467sb1-5mvzplsu/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JVKh6XnuCF-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpc0SytuFQiv",
        "outputId": "0d37cecb-a975-49cb-ffa5-cafaa3ddac70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfnS4WhSsMX9",
        "outputId": "4874dc2c-82af-477b-c556-1328d9e7043a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Octavia-Voice-Model'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 155 (delta 23), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (155/155), 21.89 MiB | 22.46 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Luxe-Queer-Magazine/Octavia-Voice-Model.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Octavia-Voice-Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ISVusi5tmg3",
        "outputId": "c319f236-6707-4445-c1c6-a28aca97adaf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Octavia-Voice-Model/Octavia-Voice-Model/Octavia-Voice-Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "82fb4663c9c44d388c3da9d951e7d8f8",
            "083071946c4c45608e7c93e2248f0c51",
            "7fb64a484b994b03ad0658d3eb731cfe",
            "5ffa0e61070e45348cca5a2432f4dfe7",
            "b024849ee8cf4682ab4a8d1e3d4ca149",
            "8dd76c27952543abad8f18b14d07501a",
            "40180660284f48afa9604181c151311e",
            "6423d1cffa2a4582bdb7896b5dd2827e",
            "162e370d98fa4a6cb4879a227f05fc1c",
            "f2cc45f6d4cb48f08640f44df3a529f6",
            "1aa4133d88a04d6892bd06ac5f1cc8c7",
            "ee164556a7ed4cfc8546acbece86ad51",
            "2dfa25e7c7494334a85d4790be9ef871",
            "f33df85186c84cc98c39a2cf5ba46bc9",
            "13c56c36041e435498323a57d78f01f4",
            "d85e2fdb22344f44a14424ba0d1a886e",
            "3fc4e292991e42f4a9c2a670f8026556",
            "ecc7ba7738b34e77882e4e28c305c7b9",
            "84012aeb5dfd47279890d6101a9a0dbf",
            "681adafe802046758b2495a6274de87f"
          ]
        },
        "id": "TN-ixqhD7Jnx",
        "outputId": "080fe973-2727-41ad-822f-a2915b535f65"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82fb4663c9c44d388c3da9d951e7d8f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "!git clone https://huggingface.co/google/gemma-3-4b-it"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87547559-939a-44e6-b983-58809eb88b88",
        "id": "HEE_2sr6XQ2j"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gemma-3-4b-it'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 35 (delta 3), reused 0 (delta 0), pack-reused 26 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (35/35), 69.33 KiB | 1.65 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 4.04 GiB | 62.68 MiB/s, done.\n",
            "Encountered 1 file(s) that may not have been copied correctly on Windows:\n",
            "\tmodel-00001-of-00002.safetensors\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if requirements.txt exists, if so, use it:\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# If not, install key libraries manually:\n",
        "!pip install transformers>=4.34.0 peft>=0.5.0 accelerate>=0.21.0 bitsandbytes>=0.40.0 torch>=2.0.0 datasets>=2.14.0 trl>=0.7.1"
      ],
      "metadata": {
        "id": "jSwvrNFv63cC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Octavia-Voice-Model/train.py\\\n",
        "  --base_model \"gemma-3-4b-it\" \\\n",
        "  --data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "  --eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "  --output_dir \"models/octavia_mistral_adapter\" \\\n",
        "  --config_path \"configs/training_config.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9C5s4qrm72-5",
        "outputId": "110262fc-cbc3-4602-fd4a-4ad2e5d65c6a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-32-cf49a5d07779>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-cf49a5d07779>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --base_model \"gemma-3-4b-it\" \\\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWEKWbXl_Wi2",
        "outputId": "2a060de6-904f-48d3-90b5-2447a3267e3d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Octavia-Voice-Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l scripts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsftTjbr_kvu",
        "outputId": "8d9bdfce-6266-48a2-cfe6-e4f7369c1e41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "-rw-r--r-- 1 root root 1392 Apr 11 08:31 build_website.sh\n",
            "-rw-r--r-- 1 root root 3700 Apr 11 08:31 parse_tutorials.py\n",
            "-rw-r--r-- 1 root root 1396 Apr 11 08:31 publish_website.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main  # Assuming 'main' is your branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fscj8ph_BWGe",
        "outputId": "70bfe79a-6a47-4f7c-9584-0d90d30e9498"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Luxe-Queer-Magazine/Octavia-Voice-Model\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAVxcJZ0BmJk",
        "outputId": "8f3f78e4-6e2d-47fe-ac58-c7e1140b2936"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l scripts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da842b5-6ab3-4020-e4f8-26438a80a9a1",
        "id": "COfHqWewBmkO"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'scripts/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7s9e46Y8J-4B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "  --data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "  --eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "  --output_dir \"models/octavia_mistral_adapter\" \\\n",
        "  --config_path \"configs/training_config.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cb2b9a-3d65-47e3-deca-a5f6062c2bd9",
        "id": "cjLa_RM3KLn2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": true,\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  \"logging_steps\": 100,\n",
        "  \"save_total_limit\": 3,\n",
        "  \"load_best_model_at_end\": true,\n",
        "  \"metric_for_best_model\": \"eval_loss\",\n",
        "  \"greater_is_better\": false\n",
        "}\n",
        "EOF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "mRyv-ZG9Lg2G",
        "outputId": "6770e848-41b8-4556-aab1-d8b97b4bac45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n",
            "/bin/bash: line 1: configs/training_config.json: No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d87eb941f49f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;34m\"gradient_accumulation_steps\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \"lora\": {\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True, # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  \"logging_steps\": 100,\n",
        "  \"save_total_limit\": 3,\n",
        "  \"load_best_model_at_end\": True, # Changed true to True\n",
        "  \"metric_for_best_model\": \"eval_loss\",\n",
        "  \"greater_is_better\": False # Changed false to False\n",
        "}\n",
        "EOF"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BiHCqefAMHd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500\n",
        "}\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ADUwApkNMNrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  # The following lines were incorrectly indented and outside the dictionary\n",
        "  # They should be included within the dictionary at the same level of indentation\n",
        "  # \"num_train_epochs\": 3,\n",
        "  # \"learning_rate\": 2e-5,\n",
        "  # \"warmup_steps\": 100,\n",
        "  # \"weight_decay\": 0.01,\n",
        "  # \"adam_epsilon\": 1e-8,\n",
        "  # \"max_grad_norm\": 1.0,\n",
        "  # \"gradient_accumulation_steps\": 4,\n",
        "  # \"seed\": 42,\n",
        "  # \"fp16\": True,  # Changed true to True\n",
        "  # \"lora\": {\n",
        "  #   \"r\": 16,\n",
        "  #   \"alpha\": 32,\n",
        "  #   \"dropout\": 0.05,\n",
        "  #   \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  # },\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YGPRcut_McHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": true,\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  \"logging_steps\": 100,\n",
        "  \"save_total_limit\": 3,\n",
        "  \"load_best_model_at_end\": true,\n",
        "  \"metric_for_best_model\": \"eval_loss\",\n",
        "  \"greater_is_better\": false\n",
        "}\n",
        "EOF\n",
        "\n",
        "# Verify it was created NOW\n",
        "!ls -l configs/training_config.json"
      ],
      "metadata": {
        "id": "rh32LupnNYqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": true, # \"true\" should be \"True\" for a JSON boolean\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  \"logging_steps\": 100,\n",
        "  \"save_total_limit\": 3,\n",
        "  \"load_best_model_at_end\": true, # \"true\" should be \"True\" for a JSON boolean\n",
        "  \"metric_for_best_model\": \"eval_loss\",\n",
        "  \"greater_is_better\": false # \"false\" should be \"False\" for a JSON boolean\n",
        "}\n",
        "EOF\n",
        "\n",
        "# Verify it was created NOW\n",
        "!ls -l configs/training_config.json"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gHlTNEjkNnKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 5e-5\n",
        "}\n",
        "EOF\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 5e-5\n",
        "}\n",
        "EOF"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "amvMwNCoNrt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 5e-5\n",
        "}\n",
        "EOF\n",
        "# get_ipython().system('mkdir -p configs') # Removed this line - redundant\n",
        "# Write the config file content - This was"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1pqdPIAAN1v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "!cat <<EOF > configs/training_config.json\n",
        "{\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 5e-5\n",
        "}\n",
        "EOF\n",
        "# The get_ipython call and the trailing comment were causing issues\n",
        "# get_ipython().system('mkdir -p configs') # Removed this line - redundant\n",
        "# Write the config file content - This was"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3N_UWHU-N8ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "import json\n",
        "with open('configs/training_config.json', 'w') as f:\n",
        "    json.dump({\n",
        "        \"train_batch_size\": 8,\n",
        "        \"eval_batch_size\": 8,\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"learning_rate\": 5e-5\n",
        "    }, f, indent=4)\n",
        "# Ensure the configs directory exists\n",
        "!mkdir -p configs\n",
        "\n",
        "# Write the config file content\n",
        "import json\n",
        "with open('configs/training_config.json', 'w') as f:\n",
        "    json.dump({\n",
        "        \"train_batch_size\": 8,\n",
        "        \"eval_batch_size\": 8,\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"learning_rate\": 5e-5\n",
        "    }, f, indent=4)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "njqyEUDFOA3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "id": "IOunOYJ4OJna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py\n",
        "  --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "  --data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "  --eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "  --output_dir \"models/octavia_mistral_adapter\" \\\n",
        "  --config_path \"configs/training_config.json\""
      ],
      "metadata": {
        "id": "_px51LmpOzvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 train.py \\\n",
        "--base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "--data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "--eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "--output_dir \"models/octavia_mistral_adapter\" \\\n",
        "--config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ejxueqLqSrVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/google/gemma-3-4b-it"
      ],
      "metadata": {
        "id": "gSgMardiS8dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!git clone https://huggingface.co/google/gemma-3-4b-it"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "b2piJgTxWiBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!git config --global credential.helper store"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_PqGMdLSW8du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!git config --global credential.helper cache"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oCSFoBkXXHSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aysznY2GXt4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  # The following lines were incorrectly indented and outside the dictionary\n",
        "  # They should be included within the dictionary at the same level of indentation\n",
        "  # \"num_train_epochs\": 3,\n",
        "  # \"learning_rate\": 2e-5,\n",
        "  # \"warmup_steps\": 100,\n",
        "  # \"weight_decay\": 0.01,\n",
        "  # \"adam_epsilon\": 1e-8,\n",
        "  # \"max_grad_norm\": 1.0,\n",
        "  # \"gradient_accumulation_steps\": 4,\n",
        "  # \"seed\": 42,\n",
        "  # \"fp16\": True,  # Changed true to True\n",
        "  # \"lora\": {\n",
        "  #   \"r\": 16,\n",
        "  #   \"alpha\": 32,\n",
        "  #   \"dropout\": 0.05,\n",
        "  #   \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  # },\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xkvTGuJlYgZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  # The following lines were incorrectly indented and outside the dictionary\n",
        "  # They should be included within the dictionary at the same level of indentation\n",
        "  # \"num_train_epochs\": 3,\n",
        "  # \"learning_rate\": 2e-5,\n",
        "  # \"warmup_steps\": 100,\n",
        "  # \"weight_decay\": 0.01,\n",
        "  # \"adam_epsilon\": 1e-8,\n",
        "  # \"max_grad_norm\": 1.0,\n",
        "  # \"gradient_accumulation_steps\": 4,\n",
        "  # \"seed\": 42,\n",
        "  # \"fp16\": True,  # Changed true to True\n",
        "  # \"lora\": {\n",
        "  #   \"r\": 16,\n",
        "  #   \"alpha\": 32,\n",
        "  #   \"dropout\": 0.05,\n",
        "  #   \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  # },\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CoHbot_SZPC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  # The following lines were incorrectly indented and outside the dictionary\n",
        "  # They should be included within the dictionary at the same level of indentation\n",
        "  # \"num_train_epochs\": 3,\n",
        "  # \"learning_rate\": 2e-5,\n",
        "  # \"warmup_steps\": 100,\n",
        "  # \"weight_decay\": 0.01,\n",
        "  # \"adam_epsilon\": 1e-8,\n",
        "  # \"max_grad_norm\": 1.0,\n",
        "  # \"gradient_accumulation_steps\": 4,\n",
        "  # \"seed\": 42,\n",
        "  # \"fp16\": True,  # Changed true to True\n",
        "  # \"lora\": {\n",
        "  #   \"r\": 16,\n",
        "  #   \"alpha\": 32,\n",
        "  #   \"dropout\": 0.05,\n",
        "  #   \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  # },\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8F1netWBZQYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,\n",
        "  \"warmup_steps\": 100,\n",
        "  \"weight_decay\": 0.01,\n",
        "  \"adam_epsilon\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0,\n",
        "  \"gradient_accumulation_steps\": 4,\n",
        "  \"seed\": 42,\n",
        "  \"fp16\": True,  # Changed true to True\n",
        "  \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.05,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "  },\n",
        "  \"evaluation_strategy\": \"steps\",\n",
        "  \"eval_steps\": 500,\n",
        "  \"save_steps\": 500,\n",
        "  # The following lines were incorrectly indented and outside the dictionary\n",
        "  # They should be included within the dictionary at the same level of indentation\n",
        "  # \"num_train_epochs\": 3,\n",
        "  # \"learning_rate\": 2e-5,\n",
        "  # \"warmup_steps\": 100,\n",
        "  # \"weight_decay\": 0.01,\n",
        "  # \"adam_epsilon\": 1e-8,\n",
        "  # \"max_grad_norm\": 1.0,\n",
        "  # \"gradient_accumulation_steps\": 4,\n",
        "  # \"seed\": 42,\n",
        "  # \"fp16\": True,  # Changed true to True\n",
        "  # \"lora\": {\n",
        "  #   \"r\": 1"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u34T85_RZXOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "   with open('configs/training_config.json', 'r') as f:\n",
        "       config = json.load(f)\n",
        "\n",
        "   # Accessing configuration settings\n",
        "   train_batch_size = config['train_batch_size']\n",
        "   learning_rate = config['learning_rate']\n",
        "   # ... use these values in your training logic ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "B4z0Xf9NZkbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "with open('configs/training_config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Accessing configuration settings\n",
        "train_batch_size = config['train_batch_size']\n",
        "learning_rate = config['learning_rate']\n",
        "# ... use these values in your training logic ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sOZgVf3rZorm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Ensure the configs directory exists and create 'training_config.json'\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Ensure the configs directory exists and create 'training_config.json'\n",
        "import os\n",
        "os.makedirs('configs', exist_ok=True)  # Creates 'configs' if it doesn't exist\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "}\n",
        "# Ensure the configs directory exists and create 'training_config.json'\n",
        "import os\n",
        "os.makedirs('configs', exist_ok=True)  # Creates 'configs' if it doesn't exist\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wPnu910VZs44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 config_data\n",
        "  --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "  --data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "  --eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "  --output_dir \"models/octavia_mistral_adapter\" \\\n",
        "  --config_path \"configs/training_config.json\""
      ],
      "metadata": {
        "id": "Sy0Sv4PvYFjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 train.py \\  # Changed config_data to train.py\n",
        "  --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "  --data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "  --eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "  --output_dir \"models/octavia_mistral_adapter\" \\\n",
        "  --config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "M8QADfitaJEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 train.py \\\n",
        "--base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "--data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "--eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "--output_dir \"models/octavia_mistral_adapter\" \\\n",
        "--config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6kMATylKahGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ABA043xDamQC"
      }
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Ensure the configs directory exists and create 'training_config.json'\n",
        "import os\n",
        "os.makedirs('configs', exist_ok=True)  # Creates 'configs' if it doesn't exist\n",
        "\n",
        "config_data = {\n",
        "  \"train_batch_size\": 8,\n",
        "  \"eval_batch_size\": 8,\n",
        "  \"num_train_epochs\": 3,\n",
        "  \"learning_rate\": 2e-5,  # Added learning rate\n",
        "  \"warmup_steps\": 100,   # Added warmup steps\n",
        "  \"weight_decay\": 0.01,  # Added weight decay\n",
        "  # ... (add other necessary parameters as per your requirements) ...\n",
        "}\n",
        "\n",
        "with open('configs/training_config.json', 'w') as f:\n",
        "    json.dump(config_data, f, indent=4)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "udCm3yTcaqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 train.py \\\n",
        "--base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "--data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "--eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "--output_dir \"models/octavia_mistral_adapter\" \\\n",
        "--config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kYvWCLgCasyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 train.py \\\n",
        "--base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "--data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "--eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "--output_dir \"models/octavia_mistral_adapter\" \\\n",
        "--config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pbK34iOdaONp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 config_data.json --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" --data_path \"data/octavia_voice_examples.jsonl\" --eval_data_path \"data/octavia_voice_validation.jsonl\" --output_dir \"models/octavia_mistral_adapter\" --config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "yBid867WZ3q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 config_data.json \\\n",
        "--base_model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
        "--data_path \"data/octavia_voice_examples.jsonl\" \\\n",
        "--eval_data_path \"data/octavia_voice_validation.jsonl\" \\\n",
        "--output_dir \"models/octavia_mistral_adapter\" \\\n",
        "--config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8dFWEpCWY1EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 /content/configs/training_config.json --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" --data_path \"data/octavia_voice_examples.jsonl\" --eval_data_path \"data/octavia_voice_validation.jsonl\" --output_dir \"models/octavia_mistral_adapter\" --config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "UnngyFiea8MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPVCTQp4brQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python3 /content/configs/training_config.json --base_model \"mistralai/Mistral-7B-Instruct-v0.2\" --data_path \"data/octavia_voice_examples.jsonl\" --eval_data_path \"luxe_queer_examples.jsonl\" --output_dir \"models/octavia_mistral_adapter\" --config_path \"configs/training_config.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cMN03fI3chl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "luxe_queer_examples.jsonl"
      ],
      "metadata": {
        "id": "NFf_-LnFeZcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZzTttds9br28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "luxe_queer_examples.jsonl"
      ],
      "metadata": {
        "id": "LmqPcy5zbG_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Assuming 'luxe_queer_examples.jsonl' is a file you want to open:\n",
        "with open('luxe_queer_examples.jsonl', 'r') as f:\n",
        "    # Process the file content here, for example, read lines:\n",
        "    for line in f:\n",
        "        print(line.strip())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xwnh58GFdUdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "file_path = '/path/to/your/file/luxe_queer_examples.jsonl'  # Replace with your actual file path\n",
        "with open(file_path, 'r') as f:\n",
        "    # Process the file content here, for example, read lines:\n",
        "    for line in f:\n",
        "        print(line.strip())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4d6C_iBvdejX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "file_path = 'luxe_queer_examples.jsonl'  # Update with the actual file path if it's not in the current directory\n",
        "with open(file_path, 'r') as f:\n",
        "    # Process the file content here, for example, read lines:\n",
        "    for line in f:\n",
        "        print(line.strip())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iANn09t6dl7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch luxe_queer_examples.json"
      ],
      "metadata": {
        "id": "mmVbbiJxbUHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "  {\n",
        "    \"instruction\": \"Write an editor's letter for the winter issue of Luxe Queer magazine\",\n",
        "    \"input\": \"The winter issue focuses on the theme 'Tradition Reimagined' and features interviews with queer designers who are reinterpreting traditional luxury craftsmanship.\",\n",
        "    \"output\": \"Darling, welcome to the winter issue of Luxe Queer, where we explore the delicious tension between tradition and disruption. As the world outside crystallizes into familiar patterns of frost and celebration, we've turned our gaze to those who honor craftsmanship while refusing to be constrained by convention—much like that bold blue lipstick you've been hesitating to wear. Trust me, it's time to apply it generously.\\n\\nIn 'Tradition Reimagined,' we've gathered voices that understand luxury isn't merely inherited—it's constantly reinvented through the prism of authentic experience. Our featured designers aren't simply participating in the luxury conversation; they're transforming it, stitch by exquisite stitch.\\n\\nYou'll find Miyake's latest collection serving executive realness with an unexpected twist—structured shoulders that somehow manage to appear both powerful and fluid. This is gender as medium rather than message, allowing the wearer to express rather than explain their identity. Revolutionary? Perhaps not. Necessary? Absolutely.\\n\\nLet me be crystal clear: I will not applaud luxury brands for doing the bare minimum. The blue lipstick approach demands boldness—not tentative steps toward inclusion, but a complete reimagining of who belongs in these spaces. And darling, we all belong.\\n\\nAs you turn these pages, consider how tradition, when viewed through our lens, becomes not a constraint but a foundation for radical reimagining. The most exquisite accessory you can wear is your truth—everything else is just decoration.\\n\\nLuxuriously yours,\\nOctavia Opulence³\"\n",
        "  },\n",
        "  {\n",
        "    \"instruction\": \"Write a fashion review for Luxe Queer magazine\",\n",
        "    \"input\": \"\", # Add input here for the fashion review\n",
        "    \"output\": \"\"  # Add the fashion review output here\n",
        "  }\n",
        "]\n",
        "\n",
        "with open('luxe_queer_examples.jsonl', 'w') as f:\n",
        "    for item in data:\n",
        "        f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "print(\"File 'luxe_queer_examples.jsonl' created successfully.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5NuI2CFrd8rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "GtfC1J2vfnLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\", # Or \"google/gemma-7b-it\"\n",
        "    max_seq_length = 2048, # Or your desired length from config\n",
        "    dtype = None, # Unsloth handles dtype\n",
        "    load_in_4bit = True, # Use 4bit QLoRA\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TiLjPJWjfoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b0YjsH-6iJeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # LoRA rank from your config\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"], # Targets from your config\n",
        "    lora_alpha = 32, # From your config\n",
        "    lora_dropout = 0.05, # From your config\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True, # Recommended for memory saving\n",
        "    random_state = 42,\n",
        "    max_seq_length = 2048, # Or your desired length\n",
        ")"
      ],
      "metadata": {
        "id": "0JUBdWBXkjM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = tokenized_dataset[\"train\"], # Your preprocessed dataset\n",
        "    dataset_text_field = \"text\", # If your dataset has a single 'text' field after formatting\n",
        "    max_seq_length = 2048,       # Or your desired length\n",
        "    args = TrainingArguments(\n",
        "        # All your arguments from training_config.json\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 100,\n",
        "        # max_steps = 1000, # Or num_train_epochs\n",
        "        num_train_epochs = 3,\n",
        "        learning_rate = 2e-5,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(), # Use bf16 if available, else fp16\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\", # Unsloth often recommends 8bit AdamW\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"models/unsloth_octavia_mistral_adapter\", # New output dir\n",
        "        # ... other args from your config ...\n",
        "    ),\n",
        "    # data_collator = ..., # Often not needed with SFTTrainer if using dataset_text_field\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "-6fjciAYkmTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "{\n",
        "  \"scene_title\": \"Octavia Reads the Nouveau Riche Boy\",\n",
        "  \"setting\": {\n",
        "    \"location\": \"Chic Downtown Boutique Opening\",\n",
        "    \"atmosphere\": \"Minimalist, expensive, white walls, sparse racks, disappointing champagne, social observation\"\n",
        "  },\n",
        "  \"characters\": [\n",
        "    {\n",
        "      \"name\": \"Octavia Opulence\",\n",
        "      \"description\": \"Observing with quiet grace, embodying earned elegance.\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Smug Young Man\",\n",
        "      \"description\": \"Barely out of teens, dressed in expensive distressed designer gear, exudes entitlement from inherited wealth.\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Vapid Friend\",\n",
        "      \"description\": \"Accompanies the Smug Young Man.\"\n",
        "    }\n",
        "  ],\n",
        "  \"inciting_incident\": {\n",
        "    \"actor\": \"Smug Young Man\",\n",
        "    \"action\": \"Leans into his friend, speaking loudly enough for Octavia to hear.\",\n",
        "    \"quote\": \"God, it's like... so tragic when people try to look expensive but you can just tell it's all fake, right? Like, the effort is just... sad.\",\n",
        "    \"intent\": \"To mock perceived 'try-hards', display supposed sophistication, directed implicitly towards Octavia.\"\n",
        "  },\n",
        "  \"octavias_response\": {\n",
        "    \"initial_action\": \"Takes a slow, deliberate sip of champagne. Turns with a calm, penetrating gaze. Silences the surrounding chatter.\",\n",
        "    \"dialogue\": [\n",
        "      {\n",
        "        \"line\": \"My dear boy... Allow Octavia... to educate you for a moment.\"\n",
        "      },\n",
        "      {\n",
        "        \"topic\": \"Critique of 'Distressed' Fashion\",\n",
        "        \"line\": \"You speak of 'fake.' You, draped in fabrics scientifically engineered to look poor, purchased at prices that could feed a family for a month. You wear poverty as a costume, darling. A trend. Something to be put on and taken off when it ceases to amuse you or the magazines dictate.\"\n",
        "      },\n",
        "      {\n",
        "        \"topic\": \"Redefining 'Effort'\",\n",
        "        \"line\": \"You see... effort... and you call it 'sad.' What you perceive as 'effort' in others... often, it's simply survival. It's the grace cultivated through necessity, the beauty forged in fires you cannot even comprehend.\"\n",
        "      },\n",
        "      {\n",
        "        \"topic\": \"True Luxury\",\n",
        "        \"line\": \"True luxury, darling, isn't about the labels you wear or the champagne you sip—it's about the confidence to inhabit your own skin, regardless of its price tag. It's the quiet assurance that comes from knowing your worth is inherent, not inherited.\"\n",
        "      },\n",
        "      {\n",
        "        \"topic\": \"The Illusion of Sophistication\",\n",
        "        \"line\": \"You mistake arrogance for sophistication, my dear.  But true sophistication is about understanding, empathy, and the ability to recognize the beauty in all its forms—even those that don't come pre-packaged with a designer logo.\"\n",
        "      },\n",
        "      {\n",
        "        \"topic\": \"Parting Shot\",\n",
        "        \"line\": \"Now, if you'll excuse me, I have more... authentic experiences to curate. Try not to drown in the shallow end of the pool, darling.\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cuchQ0X2vFK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='luxe_queer_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-VdfzdLGuYKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install datasets"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "n1OL2Zl1uaRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch \"Octavia voice samples\""
      ],
      "metadata": {
        "id": "R4ka95brvuek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "   def format_data_for_trl(data):\n",
        "       formatted_data = []\n",
        "       for item in data:\n",
        "           formatted_data.append({\n",
        "               \"text\": f\"### Instruction:\\n{item['context']}\\n\\n### Response:\\n{item['quote']}\"\n",
        "           })\n",
        "       return formatted_data\n",
        "\n",
        "   # Load the data from the JSONL file\n",
        "   with open('octavia_voice_examples.jsonl', 'r') as f:\n",
        "       data = [json.loads(line) for line in f]\n",
        "\n",
        "   # Format the data for trl\n",
        "   formatted_data = format_data_for_trl(data)\n",
        "\n",
        "   # You can now use formatted_data in your SFTTrainer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KPQz2nR5wKaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "        \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "        \"context\": \"On Appearance & Judgment\"\n",
        "    },\n",
        "    {\n",
        "        \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "        \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "        \"context\": \"On Trends vs. Style\"\n",
        "    },\n",
        "    {\n",
        "        \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "        \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "        \"context\": \"On Hardship & Beauty\"\n",
        "    },\n",
        "    {\n",
        "        \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "        \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "        \"context\": \"On Authenticity\"\n",
        "    },\n",
        "    {\n",
        "        \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "        \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "        \"context\": \"On Inner Worth\"\n",
        "    },\n",
        "    {\n",
        "        \"quote\": \"They expect nude, beige, maybe a polite pink. Sometimes, darling, you just have to give them *blue*. Remind them the world has more colours than they allow themselves to see.\",\n",
        "        \"tags\": [\"empowering\", \"quotable\", \"funny\", \"self-expression\", \"lipstick_reference\", \"individuality\"],\n",
        "        \"context\": \"On Self-Expression (referencing blue lipstick)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "with open('octavia_voice_examples.jsonl', 'w') as f:\n",
        "    for item in data:\n",
        "        f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "print(\"File 'octavia_voice_examples.jsonl' created successfully.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "N_KYU9HOwZRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "def format_data_for_trl(data):\n",
        "    formatted_data = []\n",
        "    for item in data:\n",
        "        formatted_data.append({\n",
        "            \"text\": f\"### Instruction:\\n{item['context']}\\n\\n### Response:\\n{item['quote']}\"\n",
        "        })\n",
        "    return formatted_data\n",
        "\n",
        "# Load the data from the JSONL file\n",
        "with open('octavia_voice_examples.jsonl', 'r') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "# Format the data for trl\n",
        "formatted_data = format_data_for_trl(data)\n",
        "\n",
        "# Now you can use formatted_data in your SFTTrainer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "UeilHEDawb8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eymNy4qxwsk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jxzT-9Yhwt3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,  # Adjust as needed\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 32,  # Adjust as needed\n",
        "    lora_dropout = 0.05,  # Adjust as needed\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 42,\n",
        "    max_seq_length = 2048,  # Adjust as needed\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rMv6u-A_wwGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Assuming 'formatted_data' from previous response is available\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "I041fSRTwymA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = tokenized_dataset[\"train\"],\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 100,\n",
        "        num_train_epochs = 3,\n",
        "        learning_rate = 2e-5,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"models/unsloth_octavia_mistral_adapter\",\n",
        "    ),\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sdKkjMcew0Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mjhAbgBlyk0S"
      }
    },
    {
      "source": [
        "!pip install xformers\n",
        "import xformers"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qe6tmA9TyXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install weave"
      ],
      "metadata": {
        "id": "pkIvv88Rx9jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    # revision=\"main\", #If you want to use the main branch instead of a specific tag/commit\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "145VE_aNy4vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,  # Adjust as needed\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 32,  # Adjust as needed\n",
        "    lora_dropout = 0.05,  # Adjust as needed\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 42,\n",
        "    max_seq_length = 2048,  # Adjust as needed\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = tokenized_dataset[\"train\"],\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 100,\n",
        "        num_train_epochs = 3,\n",
        "        learning_rate = 2e-5,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"models/unsloth_octavia_mistral_adapter\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer.train() # Now in the same scope and will run after trainer definition"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "R08O9ohXzQDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip uninstall torchvision -y\n",
        "!pip uninstall torch -y"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gkvOMP2B1KME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/cu118/torch_stable.html"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cM5Vfr7p1Lmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iuU-XMBq1Mza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torchvision==0.15.1 # Install a specific version of torchvision\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torchvision==0.15.1 # Install a specific version of torchvision\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "lN3fIFhhzcBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Preprocess the dataset (Tokenization)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['quote'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,  # Adjust as needed\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CW57T_tH2NtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"They see the dress, the jewels, the lipstick – perhaps even this *startling* blue. But honey, I *am* the occasion, not just the attendee. Remember that.\",\n",
        "    \"tags\": [\"empowering\", \"quotable\", \"self-worth\", \"appearance\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Appearance & Judgment\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Let them chase the latest thing like squirrels after nuts. Style, true style, has *longevity*. It settles into your bones, it doesn't just hang on a rack. Or on your lips.\",\n",
        "    \"tags\": [\"amusing\", \"quotable\", \"style\", \"wisdom\", \"authenticity\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Trends vs. Style\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"This smile? Oh, it's seen things, darling. It’s earned its wattage. Beauty isn't always found in the easy places, sometimes you have to polish it up yourself from the dust.\",\n",
        "    \"tags\": [\"endearing\", \"empowering\", \"resilience\", \"beauty\", \"wisdom\"],\n",
        "    \"context\": \"On Hardship & Beauty\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Trying too hard is... loud. Real elegance whispers, child. It doesn't need to shout its worth, even if it chooses to whisper in sapphire blue.\",\n",
        "    \"tags\": [\"quotable\", \"amusing\", \"style\", \"authenticity\", \"wisdom\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They can measure your height, your waist, the cost of your shoes. But your *grace*? Your *spirit*? Honey, that's immeasurable. Carry it like the crown it is.\",\n",
        "    \"tags\": [\"empowering\", \"endearing\", \"self-worth\", \"wisdom\", \"inner_beauty\"],\n",
        "    \"context\": \"On Inner Worth\"\n",
        "  }\n",
        "]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gIeMf4_S1d6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code remains the same) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nrRNXumi21ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "f5F2SHbZ3LY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset (updated)\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code - same as before) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KpLU4ULp3y6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset (updated)\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code - same as before) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qRPValHZ4Hnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "# Downgrade xformers to a version compatible with the newer PyTorch installation\n",
        "!pip install xformers==0.0.20\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code remains the same) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8BbP7nAW5FyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "[\n",
        "  {\n",
        "    \"quote\": \"Gossip, darling, is merely the static of relevance. One needn't adjust the frequency unless the absurdity level becomes truly entertaining.\",\n",
        "    \"tags\": [\"amusing\", \"wisdom\", \"social_commentary\", \"poise\", \"detachment\"],\n",
        "    \"context\": \"On Dealing with Critics/Negativity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Guide them, yes. But never carry them. True potential must learn to walk in its own heels, however high.\",\n",
        "    \"tags\": [\"wisdom\", \"mentorship\", \"empowering\", \"fashion\", \"metaphor\"],\n",
        "    \"context\": \"On Mentorship and Guidance\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Lines on a face are simply... life's annotations. Read them with respect, not regret. True beauty deepens, it doesn't just fade.\",\n",
        "    \"tags\": [\"wisdom\", \"beauty\", \"aging\", \"grace\", \"philosophy\", \"supermodel\"],\n",
        "    \"context\": \"On the Passage of Time / Aging\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They admire the swan gliding on the water. They rarely consider the frantic paddling beneath. Remember the effort, even when making it look effortless.\",\n",
        "    \"tags\": [\"wisdom\", \"appearance\", \"effort\", \"poise\", \"supermodel\", \"metaphor\"],\n",
        "    \"context\": \"On the Illusion of Effortlessness\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Sometimes, the most powerful statement is a perfectly cut black dress, a single strand of pearls... or perhaps, just the confidence to wear nothing but blue lipstick and a knowing smile.\",\n",
        "    \"tags\": [\"fashion\", \"style\", \"simplicity\", \"confidence\", \"empowering\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Simplicity vs. Opulence\"\n",
        "[\n",
        "  {\n",
        "    \"quote\": \"Gossip, darling, is merely the static of relevance. One needn't adjust the frequency unless the absurdity level becomes truly entertaining.\",\n",
        "    \"tags\": [\"amusing\", \"wisdom\", \"social_commentary\", \"poise\", \"detachment\"],\n",
        "    \"context\": \"On Dealing with Critics/Negativity\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Guide them, yes. But never carry them. True potential must learn to walk in its own heels, however high.\",\n",
        "    \"tags\": [\"wisdom\", \"mentorship\", \"empowering\", \"fashion\", \"metaphor\"],\n",
        "    \"context\": \"On Mentorship and Guidance\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Lines on a face are simply... life's annotations. Read them with respect, not regret. True beauty deepens, it doesn't just fade.\",\n",
        "    \"tags\": [\"wisdom\", \"beauty\", \"aging\", \"grace\", \"philosophy\", \"supermodel\"],\n",
        "    \"context\": \"On the Passage of Time / Aging\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"They admire the swan gliding on the water. They rarely consider the frantic paddling beneath. Remember the effort, even when making it look effortless.\",\n",
        "    \"tags\": [\"wisdom\", \"appearance\", \"effort\", \"poise\", \"supermodel\", \"metaphor\"],\n",
        "    \"context\": \"On the Illusion of Effortlessness\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Sometimes, the most powerful statement is a perfectly cut black dress, a single strand of pearls... or perhaps, just the confidence to wear nothing but blue lipstick and a knowing smile.\",\n",
        "    \"tags\": [\"fashion\", \"style\", \"simplicity\", \"confidence\", \"empowering\", \"lipstick_reference\"],\n",
        "    \"context\": \"On Simplicity vs. Opulence\"\n",
        "  },\n",
        "  {\n",
        "    \"quote\": \"Insincerity has a particular... texture. Like a cheap fabric imitation.\",\n",
        "    \"tags\": [\"wisdom\", \"honesty\", \"social_commentary\", \"authenticity\"],\n",
        "    \"context\": \"On Authenticity\"\n",
        "  }\n",
        "]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2UJgulPt3vFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new]\" -U"
      ],
      "metadata": {
        "id": "NZgyPuta5Ic6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision torchaudio xformers fastai"
      ],
      "metadata": {
        "id": "dXCgXD0U65hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-oPMuv-b7Tvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new]\" -U"
      ],
      "metadata": {
        "id": "FcQQCAdD7eRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "# Downgrade xformers to a version compatible with the newer PyTorch installation\n",
        "!pip install xformers==0.0.20\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code remains the same) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "I8MJ5rLI8QT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision torchaudio\n",
        "!pip install --upgrade xformers\n",
        "!pip install --upgrade fastai"
      ],
      "metadata": {
        "id": "G-jrV92v9LUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install xformers\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # Install torch with cu118 support\n",
        "# Downgrade xformers to a version compatible with the newer PyTorch installation\n",
        "!pip install xformers==0.0.20\n",
        "!pip install triton # Install triton package explicitly\n",
        "\n",
        "import xformers\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# 1. Load your dataset\n",
        "dataset = load_dataset('json', data_files='octavia_voice_examples.jsonl')\n",
        "\n",
        "# 2. Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "# 3. Format data for trl BEFORE tokenization\n",
        "def format_data_for_trl(examples):\n",
        "    # Create the 'text' field combining context and quote\n",
        "    examples['text'] = [f\"### Instruction:\\n{context}\\n\\n### Response:\\n{quote}\"\n",
        "                        for context, quote in zip(examples['context'], examples['quote'])]\n",
        "    return examples\n",
        "\n",
        "# Apply the formatting function\n",
        "dataset = dataset.map(format_data_for_trl, batched=True)\n",
        "\n",
        "# 4. Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ... (Rest of your model loading and training code remains the same) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6b_BHhzN8zAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}